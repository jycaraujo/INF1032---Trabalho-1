{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo deste trabalho � comparar diversos m�todos de classifica��o para a base de dados de qualidade de vinhos dispon�vel em https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv.\n",
    "\n",
    "Voc�s devem encontrar um bom modelo preditivo, variando:\n",
    "\n",
    "o n�mero e conjunto de features (atributos) utilizados\n",
    "o m�todo utilizado\n",
    "a configura��o do algoritmo correspondente (e.g.: n�mero k para nearest neighbors, profundidade para �rvore de decis�o)\n",
    "Voc�s devem listar algumas m�tricas de qualidade, tais como: precision, recall, accuracy e f1_score, e utilizar accuracy como base para a avalia��o final, considerando a accuracy m�dia de 10 itera��es para cada configura��o.\n",
    "\n",
    "Para assegurar que eu obterei os mesmos resultados de voc�s, voc�s devem estabelecer a semente para a gera��o dos n�meros aleat�rios (utilizados para separar os conjuntos de treinamento e teste, por exemplo), utilizando os seguintes comandos no in�cio do seu c�digo (podem utilizar uma outra semente):\n",
    "\n",
    "import random\n",
    "random.seed(1001001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "wine_raw = pd.read_csv(csv_file, sep=\";\")\n",
    "wine_data = pd.DataFrame(wine_raw)\n",
    "wine_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      "fixed acidity           1599 non-null float64\n",
      "volatile acidity        1599 non-null float64\n",
      "citric acid             1599 non-null float64\n",
      "residual sugar          1599 non-null float64\n",
      "chlorides               1599 non-null float64\n",
      "free sulfur dioxide     1599 non-null float64\n",
      "total sulfur dioxide    1599 non-null float64\n",
      "density                 1599 non-null float64\n",
      "pH                      1599 non-null float64\n",
      "sulphates               1599 non-null float64\n",
      "alcohol                 1599 non-null float64\n",
      "quality                 1599 non-null int64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "wine_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkCR1MiAkSZ3+P7+2dvkx5GTmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b986de6e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "wine_data.quality.plot(kind='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn import neighbors\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "import math\n",
    "\n",
    "# Definir seed utilizada\n",
    "seed_num = 1001001\n",
    "\n",
    "# Definir as features\n",
    "all_features = ['fixed acidity', 'volatile acidity', 'citric acid', \n",
    "            'residual sugar', 'chlorides', 'free sulfur dioxide', \n",
    "            'total sulfur dioxide', 'density', 'pH', \n",
    "            'sulphates', 'alcohol', 'quality']\n",
    "features = ['fixed acidity', 'volatile acidity', 'citric acid', \n",
    "            'residual sugar', 'chlorides', 'free sulfur dioxide', \n",
    "            'total sulfur dioxide', 'density', 'pH', \n",
    "            'sulphates', 'alcohol']\n",
    "outcome_column = 'quality'\n",
    "\n",
    "outcome_labels = sorted(list(set(wine_data.quality)))\n",
    "# print(outcome_labels)\n",
    "\n",
    "\n",
    "Y = np.array(wine_data[outcome_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_training_test(attributes, seed_number):\n",
    "    # Separar os conjuntos de treino e teste\n",
    "    Wine_Train, Wine_Test = train_test_split(wine_data, test_size=0.13, stratify=wine_data[outcome_column], random_state=np.random.seed(seed_number))\n",
    "\n",
    "    # Converter os conjuntos de treino para array\n",
    "    X_train = np.array(Wine_Train[attributes])\n",
    "    Y_train = np.array(Wine_Train[outcome_column])\n",
    "#     print(X_train.shape[0], Y_train.shape[0])\n",
    "\n",
    "    # Converter os conjuntos de teste para array\n",
    "    X_test = np.array(Wine_Test[attributes])\n",
    "    Y_test = np.array(Wine_Test[outcome_column])\n",
    "#     print(X_test.shape[0], Y_test.shape[0])\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "_Precision = 1\n",
    "_Recall = 2\n",
    "_F1Score = 3\n",
    "_Accuracy = 4\n",
    "\n",
    "_AverageOfAllScores = 1 # Calcula a precis�o/f1_score/recall de cada label e depois faz a m�dia delas\n",
    "_OverallScore = 2 # Calcula a precis�o/f1_score/recall global\n",
    "_ScoreByLabel = 3 # Calcula a precis�o/f1_score/recall de cada label e retorna elas em um array\n",
    "\n",
    "def calculateScores(real_group, pred_group, score_type, average_type):\n",
    "    if(average_type == _AverageOfAllScores):\n",
    "        chosenAverage = \"macro\"\n",
    "    elif(average_type == _OverallScore):\n",
    "        chosenAverage = \"micro\"\n",
    "    elif(average_type == _ScoreByLabel):\n",
    "        chosenAverage = None\n",
    "    \n",
    "    if(score_type == _Precision):\n",
    "        return metrics.precision_score(y_true=real_group, y_pred=pred_group, average=chosenAverage)\n",
    "    elif(score_type == _Recall):\n",
    "        return metrics.recall_score(y_true=real_group, y_pred=pred_group, average=chosenAverage)\n",
    "    elif(score_type == _F1Score):\n",
    "        return metrics.f1_score(y_true=real_group, y_pred=pred_group, average=chosenAverage)\n",
    "    elif(score_type == _Accuracy):\n",
    "        # Normalizar os dados: Calcula a acur�cia\n",
    "        # Sem normalizar os dados: Calcula o n�mero total de TP\n",
    "        return metrics.accuracy_score(y_true=real_group, y_pred=pred_group, normalize=True)\n",
    "    \n",
    "    \n",
    "scores = ['Precision', 'Recall', 'F1 Score', 'Accuracy']\n",
    "\n",
    "def showScoreResults(score_name, real_group, pred_group):\n",
    "    if(score_name == scores[0]):\n",
    "        method = _Precision\n",
    "    elif(score_name == scores[1]):\n",
    "        method = _Recall\n",
    "    elif(score_name == scores[2]):\n",
    "        method = _F1Score\n",
    "    elif(score_name == scores[3]):\n",
    "        method = _Accuracy\n",
    "        \n",
    "    if(method == _Precision or method == _Recall or method == _F1Score):\n",
    "        score = calculateScores(real_group, pred_group, method, _AverageOfAllScores)\n",
    "        print('Average of all labels' + score_name + ':', '{:6.4f}'.format(score))\n",
    "        score = calculateScores(real_group, pred_group, method, _OverallScore)\n",
    "        print('Overall' + score_name + ':', '{:6.4f}'.format(score))\n",
    "        score = calculateScores(real_group, pred_group, method, _ScoreByLabel)\n",
    "        print(score_name + ' By Label')\n",
    "        for label in outcome_labels:\n",
    "            index = outcome_labels.index(label)\n",
    "            print('Label: ' + str(label) + '\\t' + '{:6.4f}'.format(score[index]))\n",
    "    elif(method == _Accuracy):\n",
    "        score = calculateScores(real_group, pred_group, method, 0)\n",
    "        print(score_name + ':', '{:6.4f}'.format(score))\n",
    "\n",
    "def showScores_TrainAndTest():\n",
    "    for score in scores:\n",
    "        print('\\n')\n",
    "        print('# ' + score)\n",
    "        print('#')\n",
    "        print('# Training Data')\n",
    "        showScoreResults(score, Y_train, Yhat_train)\n",
    "        print('#')\n",
    "        print('# Test Data')\n",
    "        showScoreResults(score, Y_test, Yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# k-nearest neighbor (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para um dos casos de teste:\n",
      "\n",
      "Acuracia media para 10 casos de teste: 0.595673076923\n"
     ]
    }
   ],
   "source": [
    "accuracy_total = []\n",
    "seeds_split_train_test = [47, 24, 16, 394, 12, 46, 78, 20, 1, 108]\n",
    "attributes = features\n",
    "\n",
    "#Create an instance of K-nearest neighbor classifier\n",
    "knn_model = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "for i in range (0, 10):\n",
    "    X = np.array(wine_data[attributes])\n",
    "    X_train, Y_train, X_test, Y_test = define_training_test(attributes, seeds_split_train_test[i])\n",
    "\n",
    "    #Train the classifier\n",
    "    knn_model.fit(X_train,Y_train)\n",
    "\n",
    "    #Compute the prediction according to the model\n",
    "    Yhat = knn_model.predict(X_test)\n",
    "\n",
    "    if(i == 0):\n",
    "        print('Para um dos casos de teste:')\n",
    "        Yhat_train = knn_model.predict(X_train)\n",
    "#         showScores_TrainAndTest();\n",
    "\n",
    "    accuracy_total.append(metrics.accuracy_score(y_true=Y_test, y_pred=Yhat, normalize=True))\n",
    "\n",
    "accuracy_avg = np.mean(accuracy_total)\n",
    "\n",
    "print('\\nAcuracia media para 10 casos de teste: ' + str(accuracy_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para um dos casos de teste:\n",
      "\n",
      "Acuracia media para 10 casos de teste: 0.540865384615\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "accuracy_total = []\n",
    "seeds_split_train_test = [47, 24, 16, 394, 12, 46, 78, 20, 1, 108]\n",
    "attributes = features\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "for i in range (0, 10):\n",
    "    X = np.array(wine_data[attributes])\n",
    "    X_train, Y_train, X_test, Y_test = define_training_test(attributes, seeds_split_train_test[i])\n",
    "\n",
    "    #Train the classifier\n",
    "    gnb.fit(X_train,Y_train)\n",
    "\n",
    "    #Compute the prediction according to the model\n",
    "    Yhat = gnb.predict(X_test)\n",
    "\n",
    "    if(i == 0):\n",
    "        print('Para um dos casos de teste:')\n",
    "        Yhat_train = gnb.predict(X_train)\n",
    "#         showScores_TrainAndTest();\n",
    "\n",
    "    accuracy_total.append(metrics.accuracy_score(y_true=Y_test, y_pred=Yhat, normalize=True))\n",
    "\n",
    "accuracy_avg = np.mean(accuracy_total)\n",
    "\n",
    "print('\\nAcuracia media para 10 casos de teste: ' + str(accuracy_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para um dos casos de teste:\n",
      "\n",
      "Acuracia media para 10 casos de teste: 0.618269230769\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "accuracy_total = []\n",
    "seeds_split_train_test = [47, 24, 16, 394, 12, 46, 78, 20, 1, 108]\n",
    "attributes = features\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(random_state=np.random.seed(seed_num))\n",
    "\n",
    "for i in range (0, 10):\n",
    "    X = np.array(wine_data[attributes])\n",
    "    X_train, Y_train, X_test, Y_test = define_training_test(attributes, seeds_split_train_test[i])\n",
    "    \n",
    "    #Train the classifier\n",
    "    clf = clf.fit(X_train,Y_train)\n",
    "\n",
    "    #Compute the prediction according to the model\n",
    "    Yhat = clf.predict(X_test)\n",
    "\n",
    "    if(i == 0):\n",
    "        print('Para um dos casos de teste:')\n",
    "        Yhat_train = clf.predict(X_train)\n",
    "#         showScores_TrainAndTest();\n",
    "\n",
    "    accuracy_total.append(metrics.accuracy_score(y_true=Y_test, y_pred=Yhat, normalize=True))\n",
    "\n",
    "accuracy_avg = np.mean(accuracy_total)\n",
    "\n",
    "print('\\nAcuracia media para 10 casos de teste: ' + str(accuracy_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressao Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para um dos casos de teste:\n",
      "\n",
      "Acuracia media para 10 casos de teste: 0.565865384615\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "accuracy_total = []\n",
    "seeds_split_train_test = [47, 24, 16, 394, 12, 46, 78, 20, 1, 108]\n",
    "attributes = features\n",
    "\n",
    "classifier = linear_model.LogisticRegression(random_state=np.random.seed(seed_num))\n",
    "\n",
    "for i in range (0, 10):\n",
    "    X = np.array(wine_data[attributes])\n",
    "    X_train, Y_train, X_test, Y_test = define_training_test(attributes, seeds_split_train_test[i])\n",
    "    \n",
    "    #Train the classifier\n",
    "    classifier.fit(X_train, Y_train)\n",
    "\n",
    "    #Compute the prediction according to the model\n",
    "    Yhat = classifier.predict(X_test)\n",
    "\n",
    "    if(i == 0):\n",
    "        print('Para um dos casos de teste:')\n",
    "        Yhat_train = classifier.predict(X_train)\n",
    "#         showScores_TrainAndTest();\n",
    "\n",
    "    accuracy_total.append(metrics.accuracy_score(y_true=Y_test, y_pred=Yhat, normalize=True))\n",
    "\n",
    "accuracy_avg = np.mean(accuracy_total)\n",
    "\n",
    "print('\\nAcuracia media para 10 casos de teste: ' + str(accuracy_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support vector machines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para um dos casos de teste:\n",
      "\n",
      "Acuracia media para 10 casos de teste: 0.562980769231\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "accuracy_total = []\n",
    "seeds_split_train_test = [47, 24, 16, 394, 12, 46, 78, 20, 1, 108]\n",
    "attributes = features\n",
    "\n",
    "clf = svm.SVC(random_state = np.random.seed(seed_num))\n",
    "\n",
    "for i in range (0, 10):\n",
    "    X = np.array(wine_data[attributes])\n",
    "    X_train, Y_train, X_test, Y_test = define_training_test(attributes, seeds_split_train_test[i])\n",
    "    \n",
    "    #Train the classifier\n",
    "    clf.fit(X_train, Y_train)\n",
    "\n",
    "    #Compute the prediction according to the model\n",
    "    Yhat = clf.predict(X_test)\n",
    "\n",
    "    if(i == 0):\n",
    "        print('Para um dos casos de teste:')\n",
    "        Yhat_train = clf.predict(X_train)\n",
    "#         showScores_TrainAndTest();\n",
    "\n",
    "    accuracy_total.append(metrics.accuracy_score(y_true=Y_test, y_pred=Yhat, normalize=True))\n",
    "\n",
    "accuracy_avg = np.mean(accuracy_total)\n",
    "\n",
    "print('\\nAcuracia media para 10 casos de teste: ' + str(accuracy_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
